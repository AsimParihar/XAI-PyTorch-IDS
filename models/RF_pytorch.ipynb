{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "# Initializing RF program\n",
        "# ---------------------------------------------------------------------------------\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Initializing RF program')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# Importing Libraries\n",
        "# ---------------------------------------------------------------------------------\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Importing Libraries')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler, label_binarize\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, roc_curve, roc_auc_score, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "import shap\n",
        "from scipy.special import softmax\n",
        "\n",
        "# ✅ PyTorch (we don’t build an NN here, but you asked to migrate from TF → PyTorch)\n",
        "import torch\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "\n",
        "np.random.seed(0)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VM8-1W8e4L2",
        "outputId": "25ecb513-e19b-4625-94b6-b70254237227"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Initializing RF program\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------\n",
            "Importing Libraries\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "PyTorch version: 2.6.0+cu124\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "# Defining Metric Equations\n",
        "# ---------------------------------------------------------------------------------\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Defining Metric Equations')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "def print_feature_importances_shap_values(shap_values, features):\n",
        "    '''\n",
        "    Prints the feature importances based on SHAP values in an ordered way\n",
        "    shap_values -> The SHAP values calculated from a shap.Explainer object\n",
        "    features -> The name of the features, on the order presented to the explainer\n",
        "    '''\n",
        "    # Calculates the feature importance (mean absolute shap value) for each feature\n",
        "    importances = []\n",
        "    for i in range(shap_values.values.shape[1]):\n",
        "        importances.append(np.mean(np.abs(shap_values.values[:, i])))\n",
        "    # Calculates the normalized version\n",
        "    importances_norm = softmax(importances)\n",
        "    # Organize the importances and columns in a dictionary\n",
        "    feature_importances = {fea: imp for imp, fea in zip(importances, features)}\n",
        "    feature_importances_norm = {fea: imp for imp, fea in zip(importances_norm, features)}\n",
        "    # Sorts the dictionary\n",
        "    feature_importances = {k: v for k, v in sorted(feature_importances.items(), key=lambda item: item[1], reverse=True)}\n",
        "    feature_importances_norm = {k: v for k, v in sorted(feature_importances_norm.items(), key=lambda item: item[1], reverse=True)}\n",
        "    # Prints the feature importances\n",
        "    for k, v in feature_importances.items():\n",
        "        print(f\"{k} -> {v:.4f} (softmax = {feature_importances_norm[k]:.4f})\")\n",
        "\n",
        "def ACC(TP, TN, FP, FN):\n",
        "    Acc = (TP+TN)/(TP+FP+FN+TN)\n",
        "    return Acc\n",
        "\n",
        "def ACC_2 (TP, FN):\n",
        "    ac = (TP/(TP+FN))\n",
        "    return ac\n",
        "\n",
        "def PRECISION(TP, FP):\n",
        "    Precision = TP/(TP+FP)\n",
        "    return Precision\n",
        "\n",
        "def RECALL(TP, FN):\n",
        "    Recall = TP/(TP+FN)\n",
        "    return Recall\n",
        "\n",
        "def F1_score(Recall, Precision):  # renamed to avoid variable/function collision later\n",
        "    F1 = 2 * Recall * Precision / (Recall + Precision)\n",
        "    return F1\n",
        "\n",
        "def BACC(TP, TN, FP, FN):\n",
        "    BACC_val = (TP/(TP+FN)+ TN/(TN+FP))*0.5\n",
        "    return BACC_val\n",
        "\n",
        "def MCC(TP, TN, FP, FN):\n",
        "    MCC_val = (TN*TP-FN*FP)/(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN))**.5)\n",
        "    return MCC_val\n",
        "\n",
        "def AUC_ROC(y_test_bin, y_score):\n",
        "    auc_avg = 0\n",
        "    counting = 0\n",
        "    for i in range(y_test_bin.shape[1]):\n",
        "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
        "        auc_avg += auc(fpr, tpr)\n",
        "        counting = i+1\n",
        "    return auc_avg/counting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Owf6DGz2e59Z",
        "outputId": "8b63cca2-38c9-4b9b-b1fe-b1e1e628ce06"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Defining Metric Equations\n",
            "---------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------------------------------------------------------------\n",
        "# Defining features of interest\n",
        "# ---------------------------------------------------------------------------------\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Defining features of interest')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "# Keep only the final req_cols version you used\n",
        "req_cols = [\n",
        "    ' Packet Length Std', ' Total Length of Bwd Packets', ' Subflow Bwd Bytes',\n",
        "    ' Destination Port', ' Packet Length Variance', ' Bwd Packet Length Mean',' Avg Bwd Segment Size',\n",
        "    'Bwd Packet Length Max', ' Init_Win_bytes_backward','Total Length of Fwd Packets',\n",
        "    ' Subflow Fwd Bytes', 'Init_Win_bytes_forward', ' Average Packet Size', ' Packet Length Mean',\n",
        "    ' Max Packet Length',' Label'\n",
        "]\n",
        "\n",
        "# ---------------------------------------------------------------------------------\n",
        "# Loading Databases\n",
        "# ---------------------------------------------------------------------------------\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Loading Databases')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "files = [\n",
        "    'Wednesday-workingHours.pcap_ISCX.csv',\n",
        "    'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
        "    'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
        "    'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
        "    'Monday-WorkingHours.pcap_ISCX.csv',\n",
        "    'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
        "    'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv',\n",
        "    'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv'\n",
        "]\n",
        "\n",
        "frames = [pd.read_csv(file, usecols=req_cols) for file in files]\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "df = df.sample(frac=1)\n",
        "print(\"Loaded shape:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j_jpoQWe9l4",
        "outputId": "80503395-b5b7-45d2-b88b-b25c34239d39"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Defining features of interest\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------\n",
            "Loading Databases\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "Loaded shape: (2830743, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---------------------------------------------------------------------------------')\n",
        "print('Normalizing database')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "df_max_scaled = df.copy()\n",
        "y = df_max_scaled[' Label'].replace({\n",
        "    'DoS GoldenEye': 'Dos/Ddos',\n",
        "    'DoS Hulk': 'Dos/Ddos',\n",
        "    'DoS Slowhttptest': 'Dos/Ddos',\n",
        "    'DoS slowloris': 'Dos/Ddos',\n",
        "    'Heartbleed': 'Dos/Ddos',\n",
        "    'DDoS': 'Dos/Ddos',\n",
        "    'FTP-Patator': 'Brute Force',\n",
        "    'SSH-Patator': 'Brute Force',\n",
        "    'Web Attack - Brute Force': 'Web Attack',\n",
        "    'Web Attack - Sql Injection': 'Web Attack',\n",
        "    'Web Attack - XSS': 'Web Attack',\n",
        "    'Web Attack XSS': 'Web Attack',\n",
        "    'Web Attack Sql Injection': 'Web Attack',\n",
        "    'Web Attack Brute Force': 'Web Attack'\n",
        "})\n",
        "df_max_scaled.pop(' Label')\n",
        "\n",
        "for col in df_max_scaled.columns:\n",
        "    t = abs(df_max_scaled[col].max())\n",
        "    df_max_scaled[col] = df_max_scaled[col] / t\n",
        "\n",
        "df = df_max_scaled.assign(Label=y)\n",
        "df = df.fillna(0)\n",
        "print(\"After normalization:\", df.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_qrJpyLfAFe",
        "outputId": "eacae21c-2ab7-412d-b107-7bc76ecfe747"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Normalizing database\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "After normalization: (2830743, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---------------------------------------------------------------------------------')\n",
        "print('Counting labels')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "y = df.pop('Label')\n",
        "X = df\n",
        "counter = Counter(y)\n",
        "print(counter)\n",
        "\n",
        "df = X.assign(Label=y)\n",
        "df = df.drop_duplicates()\n",
        "y = df.pop('Label')\n",
        "X = df\n",
        "print('after removing duplicates:', Counter(y))\n",
        "df = X.assign(Label=y)\n",
        "\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Separating Training and Testing db')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .70\n",
        "\n",
        "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
        "features = df.columns[:len(req_cols)-1]\n",
        "\n",
        "y_train, label = pd.factorize(train['Label'])\n",
        "y_test, label1 = pd.factorize(test['Label'])\n",
        "\n",
        "print(\"Train size:\", train.shape, \"| Test size:\", test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIaGkqlefRXK",
        "outputId": "ee2f60a6-77f5-4948-bf8a-f44cc4a1c579"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Counting labels\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "Counter({'BENIGN': 2273097, 'Dos/Ddos': 380699, 'PortScan': 158930, 'Brute Force': 13835, 'Bot': 1966, 'Web Attack � Brute Force': 1507, 'Web Attack � XSS': 652, 'Infiltration': 36, 'Web Attack � Sql Injection': 21})\n",
            "after removing duplicates: Counter({'BENIGN': 848620, 'Dos/Ddos': 73395, 'PortScan': 2237, 'Bot': 785, 'Brute Force': 707, 'Web Attack � Brute Force': 91, 'Infiltration': 36, 'Web Attack � XSS': 32, 'Web Attack � Sql Injection': 17})\n",
            "---------------------------------------------------------------------------------\n",
            "Separating Training and Testing db\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "Train size: (648526, 17) | Test size: (277394, 17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---------------------------------------------------------------------------------')\n",
        "print('Defining the RF model')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=10, n_estimators=100, min_samples_split=2, n_jobs=-1)\n",
        "\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Training the model')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "start = time.time()\n",
        "model = clf.fit(train[features], y_train)\n",
        "print('ELAPSE TIME MODEL: ', (time.time() - start)/60, 'min')\n",
        "print('------------------------------------------------------------------------------')\n",
        "\n",
        "start = time.time()\n",
        "preds = clf.predict(test[features])\n",
        "print('ELAPSE TIME PREDICTION: ', (time.time() - start)/60, 'min')\n",
        "\n",
        "y_pred = clf.predict_proba(test[features])\n",
        "pred_label = label[preds]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06kk-sBMfUV6",
        "outputId": "96c4fe26-1db9-409b-b939-6127bf312c0b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Defining the RF model\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "---------------------------------------------------------------------------------\n",
            "Training the model\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "ELAPSE TIME MODEL:  2.164467533429464 min\n",
            "------------------------------------------------------------------------------\n",
            "ELAPSE TIME PREDICTION:  0.02822315295537313 min\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---------------------------------------------------------------------------------')\n",
        "print('Generating Confusion Matrix')\n",
        "print('---------------------------------------------------------------------------------\\n')\n",
        "\n",
        "confusion_matrix = pd.crosstab(\n",
        "    test['Label'], pred_label,\n",
        "    rownames=['Actual ALERT'], colnames=['Predicted ALERT'],\n",
        "    dropna=False\n",
        ").sort_index(axis=0).sort_index(axis=1)\n",
        "\n",
        "all_unique_values = sorted(set(pred_label) | set(test['Label']))\n",
        "z = np.zeros((len(all_unique_values), len(all_unique_values)))\n",
        "rows, cols = confusion_matrix.shape\n",
        "z[:rows, :cols] = confusion_matrix\n",
        "confusion_matrix = pd.DataFrame(z, columns=all_unique_values, index=all_unique_values)\n",
        "print(confusion_matrix)\n",
        "\n",
        "FP = confusion_matrix.sum(axis=0) - np.diag(confusion_matrix)\n",
        "FN = confusion_matrix.sum(axis=1) - np.diag(confusion_matrix)\n",
        "TP = np.diag(confusion_matrix)\n",
        "TN = confusion_matrix.values.sum() - (FP + FN + TP)\n",
        "\n",
        "TP_total = np.array(sum(TP), dtype=np.float64)\n",
        "TN_total = np.array(sum(TN), dtype=np.float64)\n",
        "FP_total = np.array(sum(FP), dtype=np.float64)\n",
        "FN_total = np.array(sum(FN), dtype=np.float64)\n",
        "\n",
        "Acc = ACC(TP_total, TN_total, FP_total, FN_total)\n",
        "Precision = PRECISION(TP_total, FP_total)\n",
        "Recall = RECALL(TP_total, FN_total)\n",
        "F1_total = F1_score(Recall, Precision)\n",
        "BACC_total = BACC(TP_total, TN_total, FP_total, FN_total)\n",
        "MCC_total = MCC(TP_total, TN_total, FP_total, FN_total)\n",
        "\n",
        "print('---------------------------------------------------------------------------------')\n",
        "print('Accuracy total: ', Acc)\n",
        "print('Precision total: ', Precision )\n",
        "print('Recall total: ', Recall )\n",
        "print('F1 total: ', F1_total )\n",
        "print('BACC total: ', BACC_total)\n",
        "print('MCC total: ', MCC_total)\n",
        "\n",
        "y_test_bin = label_binarize(y_test, classes=list(range(len(label))))\n",
        "n_classes = y_test_bin.shape[1]\n",
        "print('AUC_ROC total: ', AUC_ROC(y_test_bin, y_pred))\n",
        "\n",
        "for i in range(0, len(TP)):\n",
        "    Acc_i = ACC(TP[i], TN[i], FP[i], FN[i])\n",
        "    print('Accuracy: ', label[i] ,' - ' , Acc_i)\n",
        "print('---------------------------------------------------------------------------------')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Om-Z-JlfdVy",
        "outputId": "c4e0aa69-f250-4381-c622-5b685137c135"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------------------------------------------------------\n",
            "Generating Confusion Matrix\n",
            "---------------------------------------------------------------------------------\n",
            "\n",
            "                              BENIGN   Bot  Brute Force  Dos/Ddos  \\\n",
            "BENIGN                      254298.0   0.0          0.0       3.0   \n",
            "Bot                            254.0  18.0          0.0       0.0   \n",
            "Brute Force                      9.0   0.0        207.0       0.0   \n",
            "Dos/Ddos                       228.0   0.0          0.0   21449.0   \n",
            "Infiltration                    14.0   0.0          0.0       0.0   \n",
            "PortScan                       181.0   0.0          0.0       0.0   \n",
            "Web Attack � Brute Force         8.0   0.0          0.0       0.0   \n",
            "Web Attack � Sql Injection       5.0   0.0          0.0       0.0   \n",
            "Web Attack � XSS                 6.0   0.0          0.0       0.0   \n",
            "\n",
            "                            Infiltration  PortScan  Web Attack � Brute Force  \\\n",
            "BENIGN                               0.0     168.0                       0.0   \n",
            "Bot                                  0.0       0.0                       0.0   \n",
            "Brute Force                          0.0       0.0                       0.0   \n",
            "Dos/Ddos                             0.0       0.0                       0.0   \n",
            "Infiltration                         1.0       0.0                       0.0   \n",
            "PortScan                             0.0     522.0                       0.0   \n",
            "Web Attack � Brute Force             0.0       0.0                      20.0   \n",
            "Web Attack � Sql Injection           0.0       0.0                       0.0   \n",
            "Web Attack � XSS                     0.0       0.0                       0.0   \n",
            "\n",
            "                            Web Attack � Sql Injection  Web Attack � XSS  \n",
            "BENIGN                                             0.0               0.0  \n",
            "Bot                                                0.0               0.0  \n",
            "Brute Force                                        0.0               0.0  \n",
            "Dos/Ddos                                           0.0               0.0  \n",
            "Infiltration                                       0.0               0.0  \n",
            "PortScan                                           0.0               0.0  \n",
            "Web Attack � Brute Force                           0.0               0.0  \n",
            "Web Attack � Sql Injection                         0.0               0.0  \n",
            "Web Attack � XSS                                   3.0               0.0  \n",
            "---------------------------------------------------------------------------------\n",
            "Accuracy total:  0.9992958271147417\n",
            "Precision total:  0.9968312220163378\n",
            "Recall total:  0.9968312220163378\n",
            "F1 total:  0.9968312220163378\n",
            "BACC total:  0.99821756238419\n",
            "MCC total:  0.99643512476838\n",
            "AUC_ROC total:  0.660186416824328\n",
            "Accuracy:  BENIGN  -  0.9968420369582616\n",
            "Accuracy:  PortScan  -  0.9990843349171215\n",
            "Accuracy:  Dos/Ddos  -  0.9999675551742288\n",
            "Accuracy:  Web Attack � Brute Force  -  0.9991672494718703\n",
            "Accuracy:  Brute Force  -  0.9999495302710224\n",
            "Accuracy:  Bot  -  0.9987418617562024\n",
            "Accuracy:  Infiltration  -  0.99997116015487\n",
            "Accuracy:  Web Attack � XSS  -  0.99997116015487\n",
            "Accuracy:  Web Attack � Sql Injection  -  0.9999675551742288\n",
            "---------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3218138353.py:48: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  Acc_i = ACC(TP[i], TN[i], FP[i], FN[i])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop helper columns before SHAP viz\n",
        "test.pop('Label')\n",
        "test.pop('is_train')\n",
        "\n",
        "plt.clf()\n",
        "# ## Summary Bar Plot Global\n",
        "explainer = shap.TreeExplainer(clf)\n",
        "start_index = 0\n",
        "end_index = min(500, len(test))\n",
        "shap_values = explainer.shap_values(test[start_index:end_index])\n",
        "shap_obj = explainer(test[start_index:end_index])\n",
        "\n",
        "shap.summary_plot(\n",
        "    shap_values=shap_values,\n",
        "    features=test[start_index:end_index],\n",
        "    class_names=[label[i] for i in range(min(7, len(label)))],\n",
        "    show=False\n",
        ")\n",
        "plt.savefig('RF_Shap_Summary_global_cicids.png')\n",
        "plt.clf()\n",
        "\n",
        "vals = np.abs(shap_values).mean(1)\n",
        "feature_importance = pd.DataFrame(\n",
        "    list(zip(train.columns, sum(vals))),\n",
        "    columns=['col_name','feature_importance_vals']\n",
        ")\n",
        "feature_importance.sort_values(by=['feature_importance_vals'], ascending=False, inplace=True)\n",
        "print(feature_importance.head(20))\n",
        "\n",
        "# ## Summary Dot Plot (Global)\n",
        "shap.summary_plot(\n",
        "    shap_values=np.take(shap_obj.values, 0, axis=-1),\n",
        "    features=test[start_index:end_index],\n",
        "    show=False\n",
        ")\n",
        "plt.savefig('RF_Shap_Summary_Beeswarms_cicids.png')\n",
        "plt.clf()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "id": "q9dHDnOfgJNn",
        "outputId": "9943284a-b4e4-4b04-e334-8669635578f5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2635521019.py:13: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:723: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n",
            "/usr/local/lib/python3.11/dist-packages/shap/plots/_beeswarm.py:743: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  summary_legacy(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                       col_name  feature_importance_vals\n",
            "0              Destination Port                 7.377458\n",
            "2   Total Length of Bwd Packets                 5.776469\n",
            "1   Total Length of Fwd Packets                 2.490665\n",
            "4        Bwd Packet Length Mean                 0.579661\n",
            "6            Packet Length Mean                 0.297194\n",
            "3         Bwd Packet Length Max                 0.227924\n",
            "7             Packet Length Std                 0.176619\n",
            "5             Max Packet Length                 0.098193\n",
            "8        Packet Length Variance                 0.018460\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2635521019.py:31: FutureWarning: The NumPy global RNG was seeded by calling `np.random.seed`. In a future version this function will no longer use the global RNG. Pass `rng` explicitly to opt-in to the new behaviour and silence this warning.\n",
            "  shap.summary_plot(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x750 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VwzjZSkogN8m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}